<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>User Guide &mdash; monad-bayes  documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Developer Guide" href="usage.html" />
    <link rel="prev" title="Welcome to monad-bayes’s documentation!" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> monad-bayes
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">User Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#monad-bayes-vs-other-libraries">monad-bayes vs other libraries</a></li>
<li class="toctree-l2"><a class="reference internal" href="#references">References</a></li>
<li class="toctree-l2"><a class="reference internal" href="#specifying-distributions">Specifying distributions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#constructing-distributions-as-programs">Constructing distributions as programs</a></li>
<li class="toctree-l3"><a class="reference internal" href="#hard-and-soft-conditioning">Hard and soft conditioning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#performing-inference">Performing inference</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#exact-inference">Exact inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="#independent-forward-sampling">Independent forward sampling</a></li>
<li class="toctree-l3"><a class="reference internal" href="#independent-weighted-sampling">Independent weighted sampling</a></li>
<li class="toctree-l3"><a class="reference internal" href="#markov-chain-monte-carlo">Markov Chain Monte Carlo</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sequential-monte-carlo-particle-filtering">Sequential Monte Carlo (Particle Filtering)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#resample-move-sequential-monte-carlo">Resample Move Sequential Monte Carlo</a></li>
<li class="toctree-l3"><a class="reference internal" href="#particle-marginal-metropolis-hastings">Particle Marginal Metropolis Hastings</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#example-gallery">Example Gallery</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#interoperating-with-other-haskell-code">Interoperating with other Haskell code</a></li>
<li class="toctree-l2"><a class="reference internal" href="#api-docs">API docs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="usage.html">Developer Guide</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">monad-bayes</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>User Guide</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/probprog.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="user-guide">
<h1>User Guide<a class="headerlink" href="#user-guide" title="Permalink to this headline"></a></h1>
<p>Probabilistic programming is all about being able to write programs like:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">sprinkler</span><span class="w"> </span><span class="ow">::</span><span class="w"> </span><span class="kt">MonadInfer</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="ow">=&gt;</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="kt">Bool</span><span class="w"></span>
<span class="nf">sprinkler</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kr">do</span><span class="w"></span>
<span class="w">  </span><span class="n">rain</span><span class="w"> </span><span class="ow">&lt;-</span><span class="w"> </span><span class="n">bernoulli</span><span class="w"> </span><span class="mf">0.3</span><span class="w"></span>
<span class="w">  </span><span class="n">sprinkler</span><span class="w"> </span><span class="ow">&lt;-</span><span class="w"> </span><span class="n">bernoulli</span><span class="w"> </span><span class="o">$</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="n">rain</span><span class="w"> </span><span class="kr">then</span><span class="w"> </span><span class="mf">0.1</span><span class="w"> </span><span class="kr">else</span><span class="w"> </span><span class="mf">0.4</span><span class="w"></span>
<span class="w">  </span><span class="n">wet</span><span class="w"> </span><span class="ow">&lt;-</span><span class="w"> </span><span class="n">bernoulli</span><span class="w"> </span><span class="o">$</span><span class="w"> </span><span class="kr">case</span><span class="w"> </span><span class="p">(</span><span class="n">rain</span><span class="p">,</span><span class="w"> </span><span class="n">sprinkler</span><span class="p">)</span><span class="w"> </span><span class="kr">of</span><span class="w"></span>
<span class="w">    </span><span class="p">(</span><span class="kt">True</span><span class="p">,</span><span class="w"> </span><span class="kt">True</span><span class="p">)</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"> </span><span class="mf">0.98</span><span class="w"></span>
<span class="w">    </span><span class="p">(</span><span class="kt">True</span><span class="p">,</span><span class="w"> </span><span class="kt">False</span><span class="p">)</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"> </span><span class="mf">0.8</span><span class="w"></span>
<span class="w">    </span><span class="p">(</span><span class="kt">False</span><span class="p">,</span><span class="w"> </span><span class="kt">True</span><span class="p">)</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"> </span><span class="mf">0.9</span><span class="w"></span>
<span class="w">    </span><span class="p">(</span><span class="kt">False</span><span class="p">,</span><span class="w"> </span><span class="kt">False</span><span class="p">)</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"> </span><span class="mf">0.0</span><span class="w"></span>
<span class="w">  </span><span class="n">condition</span><span class="w"> </span><span class="p">(</span><span class="n">not</span><span class="w"> </span><span class="n">wet</span><span class="p">)</span><span class="w"></span>
<span class="w">  </span><span class="n">return</span><span class="w"> </span><span class="n">rain</span><span class="w"></span>
</pre></div>
</div>
<p>and doing then do inference like this:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">enumerate</span><span class="w"> </span><span class="n">sprinkler</span><span class="w"></span>
</pre></div>
</div>
<p>to get</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[(</span><span class="kc">False</span><span class="p">,</span><span class="mf">0.8914</span><span class="p">),(</span><span class="kc">True</span><span class="p">,</span><span class="mf">0.1086</span><span class="p">)]</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">sprinkler</span></code> is a distribution over values for the Boolean <code class="docutils literal notranslate"><span class="pre">rain</span></code> variable given the likelihood and observation specified above. <code class="docutils literal notranslate"><span class="pre">enumerate</span></code> is a function which performs <strong>inference</strong>: it takes the abstract distribution <code class="docutils literal notranslate"><span class="pre">sprinkler</span></code> and calculates something concrete - in this case, the probability mass function.</p>
<p><code class="docutils literal notranslate"><span class="pre">sprinkler</span></code> is a distribution specified as a program with randomness (e.g. <code class="docutils literal notranslate"><span class="pre">bernoulli</span></code>) and scoring (e.g. <code class="docutils literal notranslate"><span class="pre">condition</span></code>). Hence: probabilistic programming. The Grand Vision is that you write your statistical model as a probabilistic program and then choose or construct a method to perform inference in a statistically and computationally efficient way.</p>
<section id="monad-bayes-vs-other-libraries">
<h2>monad-bayes vs other libraries<a class="headerlink" href="#monad-bayes-vs-other-libraries" title="Permalink to this headline"></a></h2>
<p>monad-bayes is a universal probabilistic programming language, in the sense that you can express any computable distribution. In this respect it differs from Stan, which focuses instead on handling an important subset well.</p>
<p>There is a variety of universal probabilistic programming libraries and/or languages, which include WebPPL, Gen, Pyro and Edward.</p>
<p>Advantage of these other libraries/languages:</p>
<ul class="simple">
<li><p>a lot of engineering work has been put into these libraries and languages to make them practical for real-world problems. The same is not true for monad-bayes. While its core is very nice, it doesn’t come with a lot of the batteries you might want. Adam Scibior’s thesis contains this relevant paragraph: “our library implements basic versions of advanced sampling algorithms. However, their successful application in practice requires incorporating established heuristics, such as: adaptive proposal distributions, controlling resampling with effective sample size, tuning rejuvenation kernels based on population in SMC2, and so on. We believe these are largely orthogonal to the core design, so excluding them makes for a clearer and more accessible presentation of the main ideas.”</p></li>
</ul>
<p>Advantages of monad-bayes:</p>
<ul class="simple">
<li><p>probabilistic programs in monad-bayes are first class programs in Haskell. This allows all of Haskell’s expressive power to be brought to bear. You can write distributions over any datatype (lists, trees, functions, etc). You can use powerful libraries like Pipes, lens and Parsec. Everything is totally pure. You can make use of laziness. The types are invaluable. There’s no new special syntax to learn, which makes use and development much easier.</p></li>
<li><p>inference algorithms are modular. Complex inference algorithms like RMSMC or PMMH are built out of simple composable pieces.</p></li>
</ul>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline"></a></h2>
<p>Other probabilistic programming languages with fairly similar APIs include WebPPL and Gen. This cognitive-science oriented introduction to WebPPL is an excellent resource for learning about probabilistic programming: https://probmods.org/. The tutorials for Gen are also very good, particularly for learning about traces: https://github.com/probcomp/gen-quickstart/blob/master/tutorials/A%20Bottom-Up%20Introduction%20to%20Gen.ipynb.</p>
</section>
<section id="specifying-distributions">
<h2>Specifying distributions<a class="headerlink" href="#specifying-distributions" title="Permalink to this headline"></a></h2>
<p>A distribution in monad-bayes over a set <span class="math notranslate nohighlight">\(X\)</span>, is of type:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="kt">MonadInfer</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="ow">=&gt;</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="kt">X</span><span class="w"></span>
</pre></div>
</div>
<p>monad-bayes provides standard distributions, such as:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">random</span> <span class="pre">::</span> <span class="pre">MonadInfer</span> <span class="pre">m</span> <span class="pre">=&gt;</span> <span class="pre">m</span> <span class="pre">Double</span></code> : sample uniformly from <span class="math notranslate nohighlight">\([0,1]\)</span></p></li>
</ul>
<p>The full set is listed at https://hackage.haskell.org/package/monad-bayes-0.1.1.0/docs/Control-Monad-Bayes-Class.html</p>
<p>Note that these primitives already allows us to construct quite exotic distributions, like the uniform distribution over <code class="docutils literal notranslate"><span class="pre">(+)</span> <span class="pre">::</span> <span class="pre">Int</span> <span class="pre">-&gt;</span> <span class="pre">Int</span> <span class="pre">-&gt;</span> <span class="pre">Int</span></code> and <code class="docutils literal notranslate"><span class="pre">(-)</span> <span class="pre">::</span> <span class="pre">Int</span> <span class="pre">-&gt;</span> <span class="pre">Int</span> <span class="pre">-&gt;</span> <span class="pre">Int</span></code>:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">distributionOverFunctions</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">uniformD</span><span class="w"> </span><span class="p">[(</span><span class="o">+</span><span class="p">),</span><span class="w"> </span><span class="p">(</span><span class="o">-</span><span class="p">)]</span><span class="w"></span>
</pre></div>
</div>
<section id="constructing-distributions-as-programs">
<h3>Constructing distributions as programs<a class="headerlink" href="#constructing-distributions-as-programs" title="Permalink to this headline"></a></h3>
<p>monad-bayes also lets us construct new distributions out of these. <code class="docutils literal notranslate"><span class="pre">MonadInfer</span> <span class="pre">m</span></code> implies <code class="docutils literal notranslate"><span class="pre">Monad</span> <span class="pre">m</span></code> and in turn <code class="docutils literal notranslate"><span class="pre">Functor</span> <span class="pre">m</span></code>, so we can do the following:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">fmap</span><span class="w"> </span><span class="p">(</span><span class="o">&gt;</span><span class="w"> </span><span class="mf">0.5</span><span class="p">)</span><span class="w"> </span><span class="n">random</span><span class="w"> </span><span class="ow">::</span><span class="w"> </span><span class="kt">MonadInfer</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="ow">=&gt;</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="kt">Bool</span><span class="w"></span>
</pre></div>
</div>
<p>This is the uniform distribution over <span class="math notranslate nohighlight">\((0.5, 1]\)</span>.</p>
<p>As an important special case, if <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">::</span> <span class="pre">MonadInfer</span> <span class="pre">m</span> <span class="pre">=&gt;</span> <span class="pre">m</span> <span class="pre">(a,b)</span></code> is a joint distribution over two variables, then <code class="docutils literal notranslate"><span class="pre">fmap</span> <span class="pre">fst</span> <span class="pre">a</span> <span class="pre">::</span> <span class="pre">MonadInfer</span> <span class="pre">m</span> <span class="pre">=&gt;</span> <span class="pre">m</span> <span class="pre">a</span></code> <strong>marginalizes</strong> out the second variable. That is to say, <code class="docutils literal notranslate"><span class="pre">fmap</span> <span class="pre">fst</span> <span class="pre">a</span></code> is the distribution <span class="math notranslate nohighlight">\(p(a)\)</span>, where <span class="math notranslate nohighlight">\(p(a) = \int_b p(a,b)\)</span></p>
<p>The above example use only the functor instance for <code class="docutils literal notranslate"><span class="pre">m</span></code>, but we also have the monad instance, as used in:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">example</span><span class="w"> </span><span class="ow">::</span><span class="w"> </span><span class="kt">MonadInfer</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="ow">=&gt;</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="kt">Double</span><span class="w"></span>
<span class="nf">example</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">bernoulli</span><span class="w"> </span><span class="mf">0.5</span><span class="w"> </span><span class="o">&gt;&gt;=</span><span class="w"> </span><span class="p">(</span><span class="nf">\</span><span class="n">x</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="kr">then</span><span class="w"> </span><span class="n">random</span><span class="w"> </span><span class="kr">else</span><span class="w"> </span><span class="n">normal</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"></span>
</pre></div>
</div>
<p>It’s easiest to understand this distribution as a probabilistic program: it’s the distribution you get by first sampling from <code class="docutils literal notranslate"><span class="pre">bernoulli</span> <span class="pre">0.5</span></code>, then checking the result. If the result is <code class="docutils literal notranslate"><span class="pre">True</span></code>, then sample from <code class="docutils literal notranslate"><span class="pre">random</span></code>, else from <code class="docutils literal notranslate"><span class="pre">normal</span> <span class="pre">0</span> <span class="pre">1</span></code>. As a distribution, this has a PDF:</p>
<div class="math notranslate nohighlight">
\[ f(x) = 1[0\leq x \leq 1]*0.5  + \mathcal{N}(0,1)(x)*0.5  \]</div>
<!-- $$ \int\_{[0,1]} 1[x>0.5]* + (1[x\leq 0.5]*N(0,1)(x)) dx $$ -->
<p>Equivalently, we could write this in do-notation as:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">example</span><span class="w"> </span><span class="ow">::</span><span class="w"> </span><span class="kt">MonadInfer</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="ow">=&gt;</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="kt">Double</span><span class="w"></span>
<span class="nf">example</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kr">do</span><span class="w"></span>
<span class="w">  </span><span class="n">bool</span><span class="w"> </span><span class="ow">&lt;-</span><span class="w"> </span><span class="n">bernoulli</span><span class="w"> </span><span class="mf">0.5</span><span class="w"></span>
<span class="w">  </span><span class="kr">if</span><span class="w"> </span><span class="n">bool</span><span class="w"> </span><span class="kr">then</span><span class="w"> </span><span class="n">random</span><span class="w"> </span><span class="kr">else</span><span class="w"> </span><span class="n">normal</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="mi">1</span><span class="w"></span>
</pre></div>
</div>
<p><strong>A technical note</strong>: it is often tempting to read the line <code class="docutils literal notranslate"><span class="pre">bool</span> <span class="pre">&lt;-</span> <span class="pre">bernoulli</span> <span class="pre">0.5</span></code> as saying “take a sample from <code class="docutils literal notranslate"><span class="pre">bernoulli</span> <span class="pre">0.5</span></code>. But although we’ll see below that <code class="docutils literal notranslate"><span class="pre">example</span></code> can be interpreted as a sampler, there are many other interpretations, not least as a mathematical specification of a particular distribution.</p>
<p>That said, it is often useful to think of probabilistic programs as specifying distributions over <strong>program executation traces</strong>. For example, one trace of <code class="docutils literal notranslate"><span class="pre">example</span></code> as defined above is (informally): <code class="docutils literal notranslate"><span class="pre">{bernoulli</span> <span class="pre">0.5</span> <span class="pre">:</span> <span class="pre">True,</span> <span class="pre">random</span> <span class="pre">:</span> <span class="pre">0.7}</span></code>.</p>
</section>
<section id="hard-and-soft-conditioning">
<h3>Hard and soft conditioning<a class="headerlink" href="#hard-and-soft-conditioning" title="Permalink to this headline"></a></h3>
<p>monad-bayes provides a function <code class="docutils literal notranslate"><span class="pre">score</span> <span class="pre">::</span> <span class="pre">MonadInfer</span> <span class="pre">m</span> <span class="pre">=&gt;</span> <span class="pre">Log</span> <span class="pre">Double</span> <span class="pre">-&gt;</span> <span class="pre">m</span> <span class="pre">()</span></code>. (<strong>Note</strong>: <code class="docutils literal notranslate"><span class="pre">Log</span> <span class="pre">Double</span></code> is a wrapper for <code class="docutils literal notranslate"><span class="pre">Double</span></code> which stores doubles as their logarithm, and does multiplication by addition of logarithms.)</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">example</span><span class="w"> </span><span class="ow">::</span><span class="w"> </span><span class="kt">MonadInfer</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="ow">=&gt;</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="kt">Double</span><span class="w"></span>
<span class="nf">example</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kr">do</span><span class="w"></span>
<span class="w">  </span><span class="n">bool</span><span class="w"> </span><span class="ow">&lt;-</span><span class="w"> </span><span class="n">bernoulli</span><span class="w"> </span><span class="mf">0.5</span><span class="w"></span>
<span class="w">  </span><span class="n">number</span><span class="w"> </span><span class="ow">&lt;-</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="n">bool</span><span class="w"> </span><span class="kr">then</span><span class="w"> </span><span class="n">random</span><span class="w"> </span><span class="kr">else</span><span class="w"> </span><span class="n">normal</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="mi">1</span><span class="w"></span>
<span class="w">  </span><span class="n">score</span><span class="w"> </span><span class="n">number</span><span class="w"> </span>
<span class="w">  </span><span class="n">return</span><span class="w"> </span><span class="n">bool</span><span class="w"></span>
</pre></div>
</div>
<p>It’s easiest to understand this in terms of the “program execution trace” perspective described above. What the score statement does is to multiple every trace by the value of <code class="docutils literal notranslate"><span class="pre">number</span></code> in that particular trace.</p>
<p><code class="docutils literal notranslate"><span class="pre">condition</span></code> in then defined as follows:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">condition</span><span class="w"> </span><span class="ow">::</span><span class="w"> </span><span class="kt">MonadInfer</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="ow">=&gt;</span><span class="w"> </span><span class="kt">Bool</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="nb">()</span><span class="w"></span>
<span class="nf">condition</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">score</span><span class="w"> </span><span class="o">$</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="kr">then</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="kr">else</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>
</pre></div>
</div>
<p>So <code class="docutils literal notranslate"><span class="pre">condition</span> <span class="pre">b</span></code> throws away every trace in which <code class="docutils literal notranslate"><span class="pre">b</span></code> is False, and keeps all traces in which <code class="docutils literal notranslate"><span class="pre">b</span></code> is True. For example:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">example</span><span class="w"> </span><span class="ow">::</span><span class="w"> </span><span class="kt">MonadInfer</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="ow">=&gt;</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="kt">Int</span><span class="w"></span>
<span class="nf">example</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kr">do</span><span class="w"></span>
<span class="w">  </span><span class="n">n</span><span class="w"> </span><span class="ow">&lt;-</span><span class="w"> </span><span class="n">poisson</span><span class="w"> </span><span class="mf">0.5</span><span class="w"></span>
<span class="w">  </span><span class="n">condition</span><span class="w"> </span><span class="p">(</span><span class="n">n</span><span class="o">%</span><span class="mi">2</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"></span>
<span class="w">  </span><span class="n">return</span><span class="w"> </span><span class="n">n</span><span class="w"></span>
</pre></div>
</div>
<p>This describes a poisson distribution in which all even values of the random variable are marginalized out.</p>
<!-- Another use case is Bayesian inference as in:

<!-- The most intuitive way to understand `score` is to think of a probabilistic program as making a series of random choices which trace out a possible execution of the program. At any point in this series, we can interject a `score x` statement, where the value of `x` depends on the previous choices. This statement multiplies the weight of this "trace" by the score. -->
<!-- ```haskell
bayesianExample :: (Eq a, MonadInfer m) => m a -> (a -> m b) -> (b -> m a)
bayesianExample prior likelihood b = do
    a <- prior
    b' <- likelihood a
    condition (b==b')
    return a
```

Note that operationally speaking, this approach is only going to work well for discrete distributions, since `b==b'` is going to be zero-measure in the continuous case. But in the discrete case, we could for example do: -->
<!-- ```haskell
example :: MonadInfer 
example =  bayesianExample (bernoulli 0.5) (\x -> if x then bernoulli 0.8 else bernoulli 0.9) True 
``` 
-->
<!-- ```haskell
example :: MonadInfer m => m Bool
example = do 
  x <- normal 0 1
  y <- normal 0 2
  z <- normal 0 3
  return (x > y)
```

Note that in this example, commenting out the line `z <- normal 0 3` would not change the distribution at all. **But**, there is no guarantee in theory that the inference method you use knows this. More generally,  -->
<!-- **Not all ways of expressing denotationally equivalent distributions are equally useful in practice** -->
</section>
</section>
<section id="performing-inference">
<h2>Performing inference<a class="headerlink" href="#performing-inference" title="Permalink to this headline"></a></h2>
<p>To quote <a class="reference external" href="https://webppl.readthedocs.io/en/master/inference/">this page</a>, “marginal inference (or just inference) is the process of reifying the distribution on return values implicitly represented by a stochastic computation.”. That is, a probabilistic program (stochastic computation) is an abstract object and inference transforms it into something concrete, like a histogram, a list of samples, or parameters of a known distribution.</p>
<p>All inference methods in monad-bayes work with all distributions. The only exception is that exact inference only works with discrete distributions and will throw a runtime error on continuous distributions.</p>
<p><strong>The challenge of inference</strong> is that most distributions that are of interest are not as simple as <code class="docutils literal notranslate"><span class="pre">sprinkler</span></code>. They could have continuous random variables, a huge number of them, or even a number of them that is itself random. They could involve a series of observations, interspersed with other sources of randomness.</p>
<p>Designing a language in which you can specify arbitrarily complex (computable) distributions as probabilistic programs turns out to be a largely solved problem. The tools given about are sufficient for that.</p>
<p>The hard part is designing a language where you can specify how you want to do inference, because sophisticated, often approximate, inference methods are almost always necessary for the models involved in solving real world problems.</p>
<p>Two of the large classes of inference methods are <strong>sampling based methods</strong> and <strong>gradient based methods</strong>. The latter only apply to continuous probability distributions, and are not the focus of monad-bayes.</p>
<!-- For the purposes of this section, let `dist :: MonadInfer m => m a` be the distribution you want to perform inference on.  -->
<section id="exact-inference">
<h3>Exact inference<a class="headerlink" href="#exact-inference" title="Permalink to this headline"></a></h3>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">enumerate</span><span class="w"> </span><span class="ow">::</span><span class="w"> </span><span class="kt">Ord</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="ow">=&gt;</span><span class="w"> </span><span class="kt">Enumerator</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"> </span><span class="p">[(</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="kt">Double</span><span class="p">)]</span><span class="w"></span>
</pre></div>
</div>
<p>So <code class="docutils literal notranslate"><span class="pre">enumerate</span> <span class="pre">(bernoulli</span> <span class="pre">0.7)</span></code> gives you</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[(</span><span class="kc">False</span><span class="p">,</span><span class="mf">0.3</span><span class="p">),(</span><span class="kc">True</span><span class="p">,</span><span class="mf">0.7</span><span class="p">)]</span>
</pre></div>
</div>
<p><strong>Note: enumerate only works on finite discrete distributions</strong></p>
<p>It will run forever on infinite distributions like <code class="docutils literal notranslate"><span class="pre">enumerate</span> <span class="pre">(poisson</span> <span class="pre">0.7)</span></code> and will throw the following <strong>runtime</strong> error on continuous distributions as in <code class="docutils literal notranslate"><span class="pre">enumerate</span> <span class="pre">(normal</span> <span class="pre">0</span> <span class="pre">1)</span></code>:</p>
<p><em>“Exception: Infinitely supported random variables not supported in Enumerator”</em></p>
<p><strong>However</strong>, it’s totally fine to have the elements of the support be an instance of <code class="docutils literal notranslate"><span class="pre">Ord</span></code>, as in:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">fmap</span><span class="w"> </span><span class="p">(</span><span class="nf">\</span><span class="p">(</span><span class="n">ls</span><span class="p">,</span><span class="n">p</span><span class="p">)</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"> </span><span class="p">(</span><span class="n">take</span><span class="w"> </span><span class="mi">4</span><span class="w"> </span><span class="n">ls</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="p">))</span><span class="w"> </span><span class="o">$</span><span class="w"> </span><span class="n">enumerate</span><span class="w"> </span><span class="o">$</span><span class="w"> </span><span class="n">uniformD</span><span class="w"> </span><span class="p">[[</span><span class="mi">1</span><span class="o">..</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="mi">2</span><span class="o">..</span><span class="p">]]</span><span class="w"></span>
</pre></div>
</div>
<p>which gives</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span><span class="mf">0.5</span><span class="p">),([</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span><span class="mf">0.5</span><span class="p">)]</span>
</pre></div>
</div>
</section>
<section id="independent-forward-sampling">
<h3>Independent forward sampling<a class="headerlink" href="#independent-forward-sampling" title="Permalink to this headline"></a></h3>
<p>For any probabilistic program <code class="docutils literal notranslate"><span class="pre">p</span></code> without any <code class="docutils literal notranslate"><span class="pre">condition</span></code> or <code class="docutils literal notranslate"><span class="pre">factor</span></code> statements, we may do <code class="docutils literal notranslate"><span class="pre">sampleIO</span> <span class="pre">p</span></code> or <code class="docutils literal notranslate"><span class="pre">sampleSTfixed</span> <span class="pre">p</span></code> (to run with a fixed seed) to obtain a sample in an ancestral fashion. For example, consider:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">example</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kr">do</span><span class="w"></span>
<span class="w">  </span><span class="n">x</span><span class="w"> </span><span class="ow">&lt;-</span><span class="w"> </span><span class="n">bernoulli</span><span class="w"> </span><span class="mf">0.5</span><span class="w"></span>
<span class="w">  </span><span class="kr">if</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="kr">then</span><span class="w"> </span><span class="n">normal</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="kr">else</span><span class="w"> </span><span class="n">normal</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">sampleIO</span> <span class="pre">example</span></code> will produce a sample from a Bernoulli distribution with <span class="math notranslate nohighlight">\(p=0.5\)</span>, and if it is <span class="math notranslate nohighlight">\(True\)</span>, return a sample from a standard normal, else from a normal with mean 1 and std 2. ‘</p>
<p><code class="docutils literal notranslate"><span class="pre">(replicateM</span> <span class="pre">n</span> <span class="pre">.</span> <span class="pre">sampleIO)</span> <span class="pre">example</span></code> will produce a list of <code class="docutils literal notranslate"><span class="pre">n</span></code> independent samples. However, it is recommended to instead do <code class="docutils literal notranslate"><span class="pre">(sampleIO</span> <span class="pre">.</span> <span class="pre">replicateM</span> <span class="pre">n)</span> <span class="pre">example</span></code>, which will create a new model (<code class="docutils literal notranslate"><span class="pre">replicateM</span> <span class="pre">n</span> <span class="pre">example</span></code>) consisting of <code class="docutils literal notranslate"><span class="pre">n</span></code> independent draws from <code class="docutils literal notranslate"><span class="pre">example</span></code>.</p>
<p>Because <code class="docutils literal notranslate"><span class="pre">sampleIO</span> <span class="pre">example</span></code> is totally pure, it is parallelizable.</p>
</section>
<section id="independent-weighted-sampling">
<h3>Independent weighted sampling<a class="headerlink" href="#independent-weighted-sampling" title="Permalink to this headline"></a></h3>
<p>To perform weighted sampling, use:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">sampleIO</span><span class="w"> </span><span class="o">.</span><span class="w"> </span><span class="n">runWeighted</span><span class="p">)</span><span class="w"> </span><span class="ow">::</span><span class="w"> </span><span class="kt">Weighted</span><span class="w"> </span><span class="kt">SamplerIO</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"> </span><span class="kt">IO</span><span class="w"> </span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="kt">Log</span><span class="w"> </span><span class="kt">Double</span><span class="p">)</span><span class="w"></span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">Weighted</span> <span class="pre">SamplerIO</span></code> is an instance of <code class="docutils literal notranslate"><span class="pre">MonadInfer</span></code>, so we can apply this to any distribution. For example, suppose we have the distribution:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">example</span><span class="w"> </span><span class="ow">::</span><span class="w"> </span><span class="kt">MonadInfer</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="ow">=&gt;</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="kt">Bool</span><span class="w"></span>
<span class="nf">example</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kr">do</span><span class="w"></span>
<span class="w">  </span><span class="n">x</span><span class="w"> </span><span class="ow">&lt;-</span><span class="w"> </span><span class="n">bernoulli</span><span class="w"> </span><span class="mf">0.5</span><span class="w"></span>
<span class="w">  </span><span class="n">condition</span><span class="w"> </span><span class="n">x</span><span class="w"></span>
<span class="w">  </span><span class="n">return</span><span class="w"> </span><span class="n">x</span><span class="w"></span>
</pre></div>
</div>
<p>Then:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">run</span><span class="w"> </span><span class="ow">::</span><span class="w"> </span><span class="kt">IO</span><span class="w"> </span><span class="p">(</span><span class="kt">Bool</span><span class="p">,</span><span class="w"> </span><span class="kt">Log</span><span class="w"> </span><span class="kt">Double</span><span class="p">)</span><span class="w"></span>
<span class="nf">run</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="p">(</span><span class="n">sampleIO</span><span class="w"> </span><span class="o">.</span><span class="w"> </span><span class="n">runWeighted</span><span class="p">)</span><span class="w"> </span><span class="n">example</span><span class="w"></span>
</pre></div>
</div>
<p>is an IO operation which when run, will display either <code class="docutils literal notranslate"><span class="pre">(False,</span> <span class="pre">0.0)</span></code> or <code class="docutils literal notranslate"><span class="pre">(True,</span> <span class="pre">1.0)</span></code></p>
</section>
<section id="markov-chain-monte-carlo">
<h3>Markov Chain Monte Carlo<a class="headerlink" href="#markov-chain-monte-carlo" title="Permalink to this headline"></a></h3>
<p>There are several versions of metropolis hastings MCMC defined in monad-bayes. The standard version is found in Control.Monad.Bayes.Traced. You can use it as follows:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">sampleIO</span><span class="w"> </span><span class="o">.</span><span class="w"> </span><span class="n">prior</span><span class="w"> </span><span class="o">.</span><span class="w"> </span><span class="n">mh</span><span class="w"> </span><span class="n">numSteps</span><span class="p">)</span><span class="w"> </span><span class="ow">::</span><span class="w"> </span><span class="kt">Traced</span><span class="w"> </span><span class="p">(</span><span class="kt">Weighted</span><span class="w"> </span><span class="kt">SamplerIO</span><span class="p">)</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"> </span><span class="kt">IO</span><span class="w"> </span><span class="p">[</span><span class="n">a</span><span class="p">]</span><span class="w"></span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">Traced</span> <span class="pre">(Weighted</span> <span class="pre">SamplerIO)</span></code> is an instance of <code class="docutils literal notranslate"><span class="pre">MonadInfer</span></code>, so we can apply this to any distribution. For instance:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">example</span><span class="w"> </span><span class="ow">::</span><span class="w"> </span><span class="kt">MonadInfer</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="ow">=&gt;</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="kt">Bool</span><span class="w"></span>
<span class="nf">example</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kr">do</span><span class="w"></span>
<span class="w">  </span><span class="n">x</span><span class="w"> </span><span class="ow">&lt;-</span><span class="w"> </span><span class="n">bernoulli</span><span class="w"> </span><span class="mf">0.5</span><span class="w"></span>
<span class="w">  </span><span class="n">condition</span><span class="w"> </span><span class="n">x</span><span class="w"></span>
<span class="w">  </span><span class="n">return</span><span class="w"> </span><span class="n">x</span><span class="w"></span>
</pre></div>
</div>
<p>Then</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">run</span><span class="w"> </span><span class="ow">::</span><span class="w"> </span><span class="kt">IO</span><span class="w"> </span><span class="p">[</span><span class="kt">Bool</span><span class="p">]</span><span class="w"></span>
<span class="nf">run</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="p">(</span><span class="n">sampleIO</span><span class="w"> </span><span class="o">.</span><span class="w"> </span><span class="n">prior</span><span class="w"> </span><span class="o">.</span><span class="w"> </span><span class="n">mh</span><span class="w"> </span><span class="mi">10</span><span class="p">)</span><span class="w"> </span><span class="n">example</span><span class="w"></span>
</pre></div>
</div>
<p>produces 10 unbiased samples from the posterior, by using single-site trace MCMC with the Metropolis-Hastings (MH) method. This means that the random walk is over execution traces of the probabilistic program, and the proposal distribution modifies a single random variable as a time, and then uses MH for the accept-reject criterion. For example, from the above you’d get:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="kc">True</span><span class="p">,</span><span class="kc">True</span><span class="p">,</span><span class="kc">True</span><span class="p">,</span><span class="kc">True</span><span class="p">,</span><span class="kc">True</span><span class="p">,</span><span class="kc">True</span><span class="p">,</span><span class="kc">True</span><span class="p">,</span><span class="kc">True</span><span class="p">,</span><span class="kc">True</span><span class="p">,</span><span class="kc">True</span><span class="p">,</span><span class="kc">True</span><span class="p">]</span>
</pre></div>
</div>
<p>The end of the chain is the head of the list, so you can drop samples from the end of the list for burn-in.</p>
</section>
<section id="sequential-monte-carlo-particle-filtering">
<h3>Sequential Monte Carlo (Particle Filtering)<a class="headerlink" href="#sequential-monte-carlo-particle-filtering" title="Permalink to this headline"></a></h3>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">sampleIO</span><span class="o">.</span><span class="w"> </span><span class="n">runPopulation</span><span class="o">.</span><span class="w"> </span><span class="n">smcSystematic</span><span class="w"> </span><span class="n">numSteps</span><span class="w"> </span><span class="n">numParticles</span><span class="p">)</span><span class="w"> </span>
<span class="w">  </span><span class="ow">::</span><span class="w"> </span><span class="kt">Sequential</span><span class="w"> </span><span class="p">(</span><span class="kt">Population</span><span class="w"> </span><span class="kt">SamplerIO</span><span class="p">)</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"> </span><span class="kt">IO</span><span class="w"> </span><span class="p">[(</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="kt">Numeric</span><span class="o">.</span><span class="kt">Log</span><span class="o">.</span><span class="kt">Log</span><span class="w"> </span><span class="kt">Double</span><span class="p">)]</span><span class="w"></span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">Sequential</span> <span class="pre">(Population</span> <span class="pre">SamplerIO)</span></code> is an instance of <code class="docutils literal notranslate"><span class="pre">MonadInfer</span></code>, so we can apply this to any distribution. For instance, to use our now familiar <code class="docutils literal notranslate"><span class="pre">example</span></code>:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">example</span><span class="w"> </span><span class="ow">::</span><span class="w"> </span><span class="kt">MonadInfer</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="ow">=&gt;</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="kt">Bool</span><span class="w"></span>
<span class="nf">example</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kr">do</span><span class="w"></span>
<span class="w">  </span><span class="n">x</span><span class="w"> </span><span class="ow">&lt;-</span><span class="w"> </span><span class="n">bernoulli</span><span class="w"> </span><span class="mf">0.5</span><span class="w"></span>
<span class="w">  </span><span class="n">condition</span><span class="w"> </span><span class="n">x</span><span class="w"></span>
<span class="w">  </span><span class="n">return</span><span class="w"> </span><span class="n">x</span><span class="w"></span>
</pre></div>
</div>
<p>Then</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">run</span><span class="w"> </span><span class="ow">::</span><span class="w"> </span><span class="kt">IO</span><span class="w"> </span><span class="p">[</span><span class="kt">Bool</span><span class="p">]</span><span class="w"></span>
<span class="nf">run</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="p">(</span><span class="n">sampleIO</span><span class="w"> </span><span class="o">.</span><span class="w"> </span><span class="n">runPopulation</span><span class="o">.</span><span class="w"> </span><span class="n">smcSystematic</span><span class="w"> </span><span class="mi">4</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="w"> </span><span class="n">example</span><span class="w"></span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[(</span><span class="kc">True</span><span class="p">,</span><span class="mf">6.25e-2</span><span class="p">),(</span><span class="kc">True</span><span class="p">,</span><span class="mf">6.25e-2</span><span class="p">),(</span><span class="kc">True</span><span class="p">,</span><span class="mf">6.25e-2</span><span class="p">),(</span><span class="kc">True</span><span class="p">,</span><span class="mf">6.25e-2</span><span class="p">)]</span>
</pre></div>
</div>
<p>Each of these is a particle with a weight.</p>
</section>
<section id="resample-move-sequential-monte-carlo">
<h3>Resample Move Sequential Monte Carlo<a class="headerlink" href="#resample-move-sequential-monte-carlo" title="Permalink to this headline"></a></h3>
<!-- todo -->
</section>
<section id="particle-marginal-metropolis-hastings">
<h3>Particle Marginal Metropolis Hastings<a class="headerlink" href="#particle-marginal-metropolis-hastings" title="Permalink to this headline"></a></h3>
<p>This inference method takes a prior and a model separately.</p>
<!-- todo -->
<!-- Here I use "inference" to mean the process of getting from the distribution in the abstract the something concrete, like samples from it,  an expectation over it, parameters of it, or in the above case of `enumerate`, the mass of each element of the support. -->
<!-- You then want to be able to convert this abstract specification of a distribution or model into something tangible, and in the case of this simple discrete distribution, we can do so by brute force. That's what `enumerate` does. -->
<!-- It feels natural that a pure, functional, strongly typed language like Haskell should have a good story for Bayesian probability, inference, and probabilistic programming.  -->
<!-- denotation of probabilistic programs, which we then are free to interpret in myriad ways: as weighted lists, samplers, or a variety of more sophisticated programs for performing inference -->
<!-- In particular, these interpretations can be combined, and by so doing, you can built up really rather complex inference algorithms while being sure that your method is sound. And also intelligible.  -->
<!-- *The interpretation of your model is the program which performs inference on it* -->
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="example-gallery">
<h1>Example Gallery<a class="headerlink" href="#example-gallery" title="Permalink to this headline"></a></h1>
<!-- todo: link to monad-bayes examples, with graphs and how to run -->
<!-- `sprinkler` above is a great example of the two new things you can do in a probabilistic program that you can't do in other programs: you can draw from distributions, and you can *condition* on observations. For example:

```haskell
example = do
    ind <- fmap not (bernoulli 0.9)
    val <- if ind then gaussian 0 1 else poisson 0.5
    condition (val > 1)
    return ind
```

This example is contrived, in order to show a few things. First, `m` in distributions like `bernoulli 0.9 :: MonadSample m => m Bool` (the distribution `{True : 0.9, False: 0.1}`) are functors, so we can fmap over them, e.g. with `not` to get the distribution `{True : 0.1, False: 0.9}`. Second, distributions are monads, so we can draw from them and use the results as the parameters of other distributions. Third, we have a `condition` function, which throws out all values of `ind` which would result in `val <= 1`.

The fact that distributions are a monad is the essence of probabilistic programming. It allows you to express everything from simple models (Bayesian linear regression) to complex ones (hierarchical latent Dirichlet models) in a shared language. See the `models` folder (TODO LINK) for examples.

```haskell
betaBernoulli :: MonadSample m => Int -> m [Bool]
betaBernoulli n = do
  weight <- uniform 0 1
  let toss = bernoulli weight
  replicateM n toss
```

 -->
<section id="interoperating-with-other-haskell-code">
<h2>Interoperating with other Haskell code<a class="headerlink" href="#interoperating-with-other-haskell-code" title="Permalink to this headline"></a></h2>
<p>Probabilistic programs in monad-bayes are Haskell programs. This contrasts to many probabilistic programming languages, which are deeply embedded and cannot smoothly interact with their host language.</p>
<p>For example, we can use ordinary monadic combinators, as in:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">example</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="kr">do</span><span class="w"></span>
<span class="w">  </span><span class="n">x</span><span class="w"> </span><span class="ow">&lt;-</span><span class="w"> </span><span class="n">bernoulli</span><span class="w"> </span><span class="mf">0.5</span><span class="w"></span>
<span class="w">  </span><span class="n">when</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="p">(</span><span class="n">score</span><span class="w"> </span><span class="mf">0.8</span><span class="p">)</span><span class="w"></span>
<span class="w">  </span><span class="n">return</span><span class="w"> </span><span class="n">x</span><span class="w"></span>
</pre></div>
</div>
<p>or</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">example</span><span class="w"> </span><span class="ow">=</span><span class="w"> </span><span class="n">whileM</span><span class="w"> </span><span class="p">(</span><span class="n">bernoulli</span><span class="w"> </span><span class="mf">0.99</span><span class="p">)</span><span class="w"> </span><span class="p">(</span><span class="n">normal</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"></span>
</pre></div>
</div>
<p>We can use libraries like Pipes, to specify lazy distributions as in models/Pipes.hs</p>
<p>We can write probabilistic optics to update or view latent variables, as in models/Lens.hs.</p>
<p>We can define models like PCFGs using recursion schemes, as in models/PCFG.hs.</p>
<p>We can write probabilistic parsers, as in models/Parser.hs.</p>
<p>We can use monad transformers on top of our probability monad <code class="docutils literal notranslate"><span class="pre">m</span></code>, as in models/Failure.hs.</p>
<!-- And, because we're programming directly in Haskell, rather than a domain specific language (like Church, Gen, WebPPL and most other probabilistic programming languages), we can interoperate with any other Haskell concepts. Two examples: -->
</section>
<section id="api-docs">
<h2>API docs<a class="headerlink" href="#api-docs" title="Permalink to this headline"></a></h2>
<p>For API docs, see <a class="reference external" href="https://hackage.haskell.org/package/monad-bayes">hackage</a>.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Welcome to monad-bayes’s documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="usage.html" class="btn btn-neutral float-right" title="Developer Guide" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Adam Scibior.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>